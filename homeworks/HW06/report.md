# HW06 – Report

> Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12,000 строк, 30 столбцов)
- Целевая переменная: `target` (бинарная: 0 - 67.66%, 1 - 32.34%)
- Признаки: 24 числовых признака (num01-num24)
3 категориально-подобных признака с малым числом уникальных значений:
cat_contract (3 уникальных значения)
cat_region (5 уникальных значений)
cat_payment (4 уникальных значений)
Столбец id (исключен из признаков)
Признак tenure_months (числовой, продолжительность в месяцах)


## 2. Protocol

- Разбиение: train/test (75%/25%, random_state=42, stratify=y, `random_state`)
- Подбор: CV на train (5 фолдов, оптимизировали ROC-AUC)
- Метрики: Accuracy: базовая метрика, показывает общую долю правильных предсказаний
F1: важна из-за дисбаланса классов (32% положительного класса), учитывает precision и recall
ROC-AUC: выбрана как основная метрика для сравнения моделей, так как показывает качество ранжирования и устойчива к дисбалансу

## 3. Models

DecisionTreeClassifier:
Контроль сложности через max_depth (3, 5, 7, 10, None), min_samples_split (2, 5, 10), min_samples_leaf (1, 2, 4), criterion (gini, entropy)
Всего: 5×3×3×2 = 90 комбинаций
RandomForestClassifier:
n_estimators (50, 100), max_depth (5, 10, None), min_samples_split (2, 5), min_samples_leaf (1, 2), max_features ('sqrt', 'log2')
Всего: 2×3×2×2×2 = 48 комбинаций
GradientBoostingClassifier:
n_estimators (50, 100), learning_rate (0.01, 0.1, 0.2), max_depth (3, 5), min_samples_split (2, 5), subsample (0.8, 1.0)
Всего: 2×3×2×2×2 = 48 комбинаций
StackingClassifier (опционально):
Базовые модели: DecisionTree (max_depth=5), RandomForest (n_estimators=50), GradientBoosting (n_estimators=50, learning_rate=0.1)
Мета-модель: LogisticRegression
CV-логика: 5 фолдов


## 4. Results

Модель	          Accuracy	 F1	    ROC-AUC
Dummy	               0.6767	0.0000	0.5000
LogisticRegression	   0.8297	0.7147	0.8789
DecisionTree	       0.8690	0.7756	0.9056
RandomForest	       0.9303	0.8866	0.9694
GradientBoosting	   0.9313	0.8905	0.9718
Stacking	           0.9330	0.8942	0.9694
- Победитель: GradientBoostingClassifier


Объяснение: GradientBoosting показал наилучший ROC-AUC (0.9718), который был выбран как основной критерий сравнения
Также показал лучший F1-score (0.8905) и второй по величине accuracy (0.9313)
RandomForest показал очень близкий результат (ROC-AUC=0.9694), но GradientBoosting немного превосходит его по всем метрикам


## 5. Analysis
Устойчивость:
Для проверки устойчивости были выполнены 5 прогонов с разными random_state (42, 123, 321, 777, 999) для двух лучших моделей:

GradientBoosting: ROC-AUC колебания ±0.003 (0.969-0.972)
RandomForest: ROC-AUC колебания ±0.004 (0.966-0.971)
Модели демонстрируют хорошую устойчивость к изменению random seed.
Ошибки (confusion matrix для лучшей модели - GradientBoosting):
[[1956   74]
 [ 132  838]]
TP=838, TN=1956, FP=74, FN=132
Комментарий: Модель хорошо справляется с предсказанием обоих классов. Ложных положительных (FP) меньше, чем ложных отрицательных (FN), что ожидаемо при дисбалансе классов. Precision = 91.9%, Recall = 86.4%, что дает F1=0.8905.
Выводы:

Наиболее важными оказались числовые признаки (num18, num19, num07)
Категориальные признаки не вошли в топ-15, что может указывать на их меньшую информативность
Признаки с высокой важностью имеют низкую дисперсию (стабильный вклад)
Топ-признаки вносят существенный вклад в качество модели (удаление num18 снижает ROC-AUC на ~8.4%)



## 6. Conclusion

1) Aнсамблевые методы значительно превосходят одиночные модели: RandomForest и GradientBoosting улучшили ROC-AUC на 6-9% по сравнению с DecisionTree и на 9% по сравнению с LogisticRegression.
2) Контроль сложности важен: Ограничение глубины дерева в DecisionTree (max_depth=10 вместо None) предотвратило переобучение и дало лучший результат на тесте.
3) GradientBoosting показал наилучшие результаты среди всех моделей, демонстрируя преимущество последовательного обучения над параллельным (как в RandomForest).
4) Стратификация при split и использование CV критически важны: Без стратификации оценки были бы смещенными из-за дисбаланса классов. CV обеспечил надежную оценку качества на этапе подбора параметров.
5) Permutation importance предоставляет интерпретируемые результаты, которые согласуются с feature_importances_ деревьев и помогают понять, какие признаки действительно важны для модели.
6) Честный ML-протокол (train/test split + CV на train + однократная оценка на test) позволил получить надежные и воспроизводимые результаты, избежав переобучения и оптимистичных оценок.
