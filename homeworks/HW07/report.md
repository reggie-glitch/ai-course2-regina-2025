# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов
- Признаки: 8 числовых признаков (f01-f08) + sample_id, категориальных нет
- Пропуски: нет (0 пропущенных значений)
- "Подлости" датасета: разные шкалы признаков (std от 0.50 до 60.79 - разница 120 раз), без масштабирования кластеризация невозможна, признаки с разными диапазонами значений

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 столбцов
- Признаки: 3 числовых признака (x1, x2, z_noise) + sample_id, категориальных нет
- Пропуски: нет (0 пропущенных значений)
- "Подлости" датасета: нелинейная структура + выбросы + лишний шумовой признак (z_noise), KMeans должен проигрывать из-за нелинейности

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 5 столбцов
- Признаки: 4 числовых признака + sample_id, категориальных нет
- Пропуски: нет (0 пропущенных значений)
- "Подлости" датасета: кластеры разной плотности + фоновый шум, сложность выбора eps для DBSCAN

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: масштабирование StandardScaler (обязательно для всех датасетов), обработка пропусков SimpleImputer(strategy='median'), ColumnTransformer для воспроизводимости, все признаки числовые - кодирование не требуется
- Поиск гиперпараметров:
  - KMeans: k = 2-20 для всех датасетов, random_state=42, n_init=10
  - DBSCAN: eps = 0.1-2.0 для ds1, 0.1-1.0 для ds2, 0.05-0.5 для ds3; min_samples = [3, 5, 10] для всех
  - Руководствовались максимизацией Silhouette Score при выборе "лучшего"
- Метрики: silhouette_score, davies_bouldin_score, calinski_harabasz_score; для DBSCAN метрики считались на non-noise точках
- Визуализация: PCA(2D) с random_state=42 для всех датасетов, создано по 2 графика PCA на датасет + графики подбора параметров

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для каждого из 3 датасетов:

- KMeans (поиск `k` в диапазоне 2-20, фиксировали `random_state=42`, `n_init=10`)
- DBSCAN (подбор `eps` в диапазоне, зависящем от датасета, `min_samples` [3, 5, 10], анализ доли шума)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN с eps=2.000, min_samples=10 (метрики идентичны KMeans)
- Метрики (silhouette / DB / CH): 0.5216 / 0.6853 / 11786.95
- Если был DBSCAN: доля шума 0.0% (все точки отнесены к кластерам)
- Коротко: данные имеют чёткую структуру с двумя хорошо разделёнными кластерами (2400 и 9600 точек), оба алгоритма дали идентичные результаты

### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN с eps=0.100, min_samples=10
- Метрики (silhouette / DB / CH): 0.5812 / 0.5780 / 2758.12 (KMeans: 0.4153 / 0.5858 / 44.23)
- Если был DBSCAN: доля шума 91.85%, найдено 46 кластеров
- Коротко: KMeans проигрывает DBSCAN (silhouette 0.4153 vs 0.5812), что подтверждает нелинейную структуру данных, DBSCAN обнаружил множество мелких кластеров с высокой долей шума

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN с eps=0.050, min_samples=3
- Метрики (silhouette / DB / CH): 0.8661 / 0.1585 / 6029.39 (KMeans: 0.3155 / 1.1577 / 6957.16)
- Если был DBSCAN: доля шума 99.65%, найдено 17 кластеров
- Коротко: DBSCAN значительно превосходит KMeans по silhouette (0.8661 vs 0.3155), но создаёт 99.65% шума, что соответствует описанию "кластеры разной плотности + фоновый шум"

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? На dataset-02 (silhouette 0.4153) и dataset-03 (silhouette 0.3155) из-за нелинейной структуры и разной плотности кластеров. KMeans предполагает сферические кластеры одинакового размера.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему? На dataset-02 (silhouette 0.5812) и dataset-03 (silhouette 0.8661), где важна плотность и форма кластеров. DBSCAN хорошо обнаруживает выбросы и работает с нелинейными структурами.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)? 1) Масштабирование критично для dataset-01, 2) Плотность и нелинейность для dataset-02 и dataset-03, 3) Шумовые признаки (z_noise в dataset-02) ухудшают качество KMeans.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans с разными random_state (42, 123, 456, 789, 1000) для dataset-01 с k=2
- Что получилось: все 5 запусков дали абсолютно идентичные разбиения, ARI = 1.000 для всех пар сравнений, стандартное отклонение 0.0000
- Вывод: устойчиво - KMeans показывает абсолютную устойчивость на dataset-01, что свидетельствует о чётко определённых кластерах и стабильной структуре данных

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры: через PCA визуализацию, анализ размеров кластеров, распределений признаков и доли шума
- 3-6 строк выводов: dataset-01 разделяется на 2 неравных кластера (2400 и 9600 точек) с хорошей разделимостью; dataset-02 имеет сложную структуру с 91.85% шума; dataset-03 представляет собой в основном фоновый шум (99.65%) с редкими плотными областями. PCA визуализация подтверждает эти наблюдения.

## 6. Conclusion

1. Масштабирование критически важно для датасетов с разными шкалами признаков (dataset-01)
2. DBSCAN предпочтительнее для данных с нелинейной структурой (dataset-02) и разной плотностью (dataset-03)
3. KMeans хорошо работает на сферических кластерах с одинаковой плотностью (dataset-01)
4. Выбор параметров DBSCAN (eps) сложен для данных с разной плотностью кластеров (dataset-03 показал 99.65% шума)
5. Несколько метрик обеспечивают комплексную оценку качества кластеризации (silhouette, Davies-Bouldin, Calinski-Harabasz)
6. Визуализация (PCA) обязательна для проверки результатов и понимания структуры данных
7. Проверка устойчивости показывает надёжность решения (dataset-01 показал абсолютную устойчивость ARI=1.000)
8. Фиксированные random_state обеспечивают воспроизводимость эксперимента
9. Шумовые признаки могут значительно ухудшить качество кластеризации KMeans (dataset-02)
10. Высокая доля шума в DBSCAN может указывать на фоновый шум в данных (dataset-03)